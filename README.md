 ğŸ“Œ Proyecto: Data Pipeline de Ventas

Este proyecto implementa un pipeline completo y automatizado para procesar datos de ventas utilizando una arquitectura moderna:

- ğŸ˜ **PostgreSQL** (almacenamiento)
- ğŸ **Python** (ETL, anÃ¡lisis y dashboards)
- ğŸ³ **Docker & Docker Compose**
- ğŸŒ¬ **Apache Airflow 2.6.3** (orquestaciÃ³n)
- ğŸ“Š **Plotly / Matplotlib** (visualizaciÃ³n)

El objetivo es simular un flujo real de datos corporativos, procesarlos y generar reportes diarios, todo automatizado con Airflow.

---

## ğŸ— Arquitectura del Pipeline

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Datos Iniciales â”‚ â† clientes.csv / productos.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â†“
GeneraciÃ³n de Ã“rdenes (Python)
â†“
ETL hacia PostgreSQL (Python)
â†“
AnÃ¡lisis y KPI de Ventas (Python)
â†“
Dashboards AutomÃ¡ticos â†’ PNG (Plotly/Matplotlib)
â†“
OrquestaciÃ³n con Airflow (pipeline_ventas)

yaml
Copiar cÃ³digo

---

## ğŸ“‚ Estructura del Proyecto

data-pipeline-ventas/
â”‚
â”œâ”€â”€ airflow/
â”‚ â””â”€â”€ pipeline_ventas.py
â”‚
â”œâ”€â”€ dags/ # Carpeta usada por Airflow
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ clientes.csv
â”‚ â”œâ”€â”€ productos.csv
â”‚ â””â”€â”€ ordenes.csv
â”‚
â”œâ”€â”€ docker/
â”‚ â”œâ”€â”€ docker-compose.yml
â”‚ â””â”€â”€ docker-compose-airflow.yml
â”‚
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ top_clientes.png
â”‚ â”œâ”€â”€ top_productos.png
â”‚ â””â”€â”€ ventas_por_dia.png
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ conexion_postgres.py
â”‚ â”œâ”€â”€ insertar_clientes.py
â”‚ â”œâ”€â”€ etl_productos.py
â”‚ â”œâ”€â”€ generar_ordenes.py
â”‚ â”œâ”€â”€ analisis_ventas.py
â”‚ â””â”€â”€ dashboard_ventas.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copiar cÃ³digo

---

## ğŸš€ CÃ³mo ejecutar el proyecto

### 1ï¸âƒ£ Clonar el repositorio

```bash
git clone https://github.com/CarlosGutierrezR/data-pipeline-ventas.git
cd data-pipeline-ventas
ğŸ˜ 2ï¸âƒ£ Levantar PostgreSQL + Adminer
Entrar a la carpeta docker:

bash
Copiar cÃ³digo
cd docker
docker compose up -d
Adminer estarÃ¡ disponible en:

ğŸ‘‰ http://localhost:8080

Credenciales

Campo	Valor
Servidor	postgres
Usuario	admin
ContraseÃ±a	admin
Base de datos	ventasdb

ğŸŒ¬ 3ï¸âƒ£ Levantar Airflow
Desde la carpeta docker/:

bash
Copiar cÃ³digo
docker compose -f docker-compose-airflow.yml up -d
Airflow estarÃ¡ disponible en:

ğŸ‘‰ http://localhost:8081

Credenciales Airflow

Usuario	ContraseÃ±a
airflow	airflow

â–¶ï¸ 4ï¸âƒ£ Ejecutar el Pipeline
En la interfaz web de Airflow:

Buscar el DAG: pipeline_ventas

Activarlo ğŸ”µ

Clic en Trigger DAG

Esto ejecutarÃ¡ automÃ¡ticamente:

âœ” InserciÃ³n de clientes
âœ” InserciÃ³n de productos
âœ” GeneraciÃ³n de Ã³rdenes
âœ” ETL hacia PostgreSQL
âœ” AnÃ¡lisis de mÃ©tricas de ventas
âœ” Dashboards automÃ¡ticos en PNG

ğŸ“Š 5ï¸âƒ£ Reportes generados
Los archivos se guardan en:

bash
Copiar cÃ³digo
/reports/
â”‚â”€â”€ top_clientes.png
â”‚â”€â”€ top_productos.png
â””â”€â”€ ventas_por_dia.png
AnÃ¡lisis realizados:
â­ Top 5 clientes por nÃºmero de compras

ğŸ›’ Productos mÃ¡s vendidos

ğŸ“… Ventas totales por dÃ­a

ğŸ§  DescripciÃ³n de Scripts
Script	FunciÃ³n
conexion_postgres.py	ConexiÃ³n centralizada a PostgreSQL
insertar_clientes.py	Poblar tabla de clientes
etl_productos.py	Poblar tabla de productos
generar_ordenes.py	Crear Ã³rdenes aleatorias
analisis_ventas.py	CÃ¡lculo de KPIs y mÃ©tricas
dashboard_ventas.py	GeneraciÃ³n de grÃ¡ficos PNG
pipeline_ventas.py	OrquestaciÃ³n completa del pipeline en Airflow

âš™ï¸ TecnologÃ­as Utilizadas
Apache Airflow 2.6.3

PostgreSQL 13

Docker & Docker Compose

Python 3.10

pandas / SQLAlchemy

Plotly / Matplotlib

Redis

ğŸ“¦ Requerimientos (solo si ejecutas Python manualmente)
bash
Copiar cÃ³digo
pip install -r requirements.txt
ğŸ‘¨â€ğŸ’» Autor
Proyecto desarrollado por Carlos Gutierrez R.
