ğŸ“Œ Proyecto: Data Pipeline de Ventas

Este proyecto implementa un pipeline completo y automatizado de procesamiento de datos de ventas, utilizando una arquitectura moderna basada en:

ğŸ˜ PostgreSQL (almacenamiento)

ğŸ Python (ETL, anÃ¡lisis, reportes)

ğŸ³ Docker & Docker Compose (contenedorizaciÃ³n)

ğŸŒ¬ï¸ Apache Airflow 2.6.3 (orquestaciÃ³n)

ğŸ“Š Plotly / Matplotlib (visualizaciÃ³n de datos)

El objetivo principal es simular un flujo real de datos corporativos, procesarlos y generar reportes diarios, totalmente automatizados por Airflow.

ğŸ§± Arquitectura del Pipeline
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚     Datos Iniciales     â”‚
            â”‚ (clientes / productos)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚ Generar Ã“rdenes â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ ETL a PostgreSQL â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ AnÃ¡lisis y KPI de Ventas     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Dashboards (PNG automÃ¡ticos)  â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Todo el flujo estÃ¡ orquestado por Airflow en un DAG llamado pipeline_ventas.

ğŸ“‚ Estructura del Proyecto
data-pipeline-ventas/
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ pipeline_ventas.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”œâ”€â”€ productos.csv
â”‚   â””â”€â”€ ordenes.csv
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ docker-compose-airflow.yml
â”‚   â””â”€â”€ README_docker.md
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ top_clientes.png
â”‚   â”œâ”€â”€ top_productos.png
â”‚   â””â”€â”€ ventas_por_dia.png
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ analisis_ventas.py
â”‚   â”œâ”€â”€ conexion_postgres.py
â”‚   â”œâ”€â”€ dashboard_ventas.py
â”‚   â”œâ”€â”€ etl_productos.py
â”‚   â”œâ”€â”€ generar_ordenes.py
â”‚   â””â”€â”€ insertar_clientes.py
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

âš™ï¸ TecnologÃ­as
Componente	DescripciÃ³n
Airflow 2.6.3	OrquestaciÃ³n del pipeline
PostgreSQL 13	Base de datos
Python 3.10+	Scripts ETL, anÃ¡lisis, dashboards
Docker Compose	ContenedorizaciÃ³n completa
Plotly / Matplotlib	Dashboards automÃ¡ticos
ğŸš€ CÃ³mo ejecutar el proyecto
1ï¸âƒ£ Clonar el repositorio
git clone https://github.com/CarlosGutierrezR/data-pipeline-ventas.git
cd data-pipeline-ventas

2ï¸âƒ£ Levantar los servicios con Docker

Entrar en la carpeta docker:

cd docker


Levantar Airflow, Redis y PostgreSQL:

docker compose -f docker-compose-airflow.yml up -d


Airflow estarÃ¡ disponible en:

ğŸ‘‰ http://localhost:8081

3ï¸âƒ£ Credenciales de acceso a Airflow
Usuario	ContraseÃ±a
airflow	airflow
4ï¸âƒ£ Ejecutar el pipeline

En Airflow:

â¡ï¸ Busca el DAG: pipeline_ventas
â¡ï¸ ActÃ­valo
â¡ï¸ Haz clic en Trigger DAG

Esto ejecutarÃ¡ automÃ¡ticamente todos los scripts del pipeline:

âœ” InserciÃ³n de clientes
âœ” InserciÃ³n de productos
âœ” GeneraciÃ³n de Ã³rdenes
âœ” ETL hacia PostgreSQL
âœ” AnÃ¡lisis de ventas
âœ” Dashboards automÃ¡ticos

ğŸ“Š Reportes generados

Los archivos se guardan en:

/reports/
    top_clientes.png
    top_productos.png
    ventas_por_dia.png


Ejemplo de anÃ¡lisis realizado:

Top 5 clientes por nÃºmero de Ã³rdenes

Productos mÃ¡s vendidos

Ventas totales por dÃ­a

ğŸ“œ DescripciÃ³n de Scripts
Script	FunciÃ³n
conexion_postgres.py	Conexion centralizada a PostgreSQL
insertar_clientes.py	Poblar tabla de clientes
etl_productos.py	Poblar tabla de productos
generar_ordenes.py	Crear Ã³rdenes aleatorias y guardarlas
analisis_ventas.py	Calcular mÃ©tricas y KPIs
dashboard_ventas.py	Generar grÃ¡ficos PNG
pipeline_ventas.py	OrquestaciÃ³n en Airflow
ğŸ“¦ Requerimientos

Archivo requirements.txt:

pandas
psycopg2-binary
matplotlib
plotly
kaleido
apache-airflow==2.6.3

ğŸ› ï¸ Mejoras futuras

âœ” Agregar notificaciones por correo
âœ” Contenerizar scripts en Docker
âœ” Crear API para exponer KPIs
âœ” AÃ±adir tests unitarios
âœ” Integrar CI/CD con GitHub Actions

ğŸ‘¨â€ğŸ’» Autor

Carlos Gutierrez
Ingeniero de Sistemas | Ciberseguridad | Data Engineering

ğŸ“§ chgut31@gmail.com

ğŸ”— GitHub: https://github.com/CarlosGutierrezR
